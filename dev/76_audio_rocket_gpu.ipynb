{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.basics import *\n",
    "from local.data.all import *\n",
    "from local.vision.core import *\n",
    "from local.notebook.showdoc import show_doc\n",
    "from local.audio.core import *\n",
    "from local.audio.augment import *\n",
    "from local.vision.learner import *\n",
    "from local.vision.models.xresnet import *\n",
    "from local.metrics import *\n",
    "from local.callback.schedule import *\n",
    "import torchaudio\n",
    "from fastprogress import progress_bar as pb\n",
    "from numba import njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p10speakers = Config()['data_path'] / 'ST-AEDS-20180100_1-OS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = AudioGetter(\"\", recurse=True, folders=None)\n",
    "files_10  = x(p10speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3842) [/home/jupyter/.fastai/data/ST-AEDS-20180100_1-OS/f0004_us_f0004_00446.wav,/home/jupyter/.fastai/data/ST-AEDS-20180100_1-OS/m0002_us_m0002_00128.wav,/home/jupyter/.fastai/data/ST-AEDS-20180100_1-OS/f0003_us_f0003_00279.wav,/home/jupyter/.fastai/data/ST-AEDS-20180100_1-OS/f0001_us_f0001_00168.wav,/home/jupyter/.fastai/data/ST-AEDS-20180100_1-OS/f0005_us_f0005_00286.wav,/home/jupyter/.fastai/data/ST-AEDS-20180100_1-OS/m0005_us_m0005_00282.wav,/home/jupyter/.fastai/data/ST-AEDS-20180100_1-OS/f0005_us_f0005_00432.wav,/home/jupyter/.fastai/data/ST-AEDS-20180100_1-OS/f0005_us_f0005_00054.wav,/home/jupyter/.fastai/data/ST-AEDS-20180100_1-OS/m0004_us_m0004_00110.wav,/home/jupyter/.fastai/data/ST-AEDS-20180100_1-OS/m0003_us_m0003_00180.wav...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa = OpenAudio(files_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_LENGTH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3842' class='' max='3842', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3842/3842 00:54<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labeler = lambda x: str(x).split('/')[-1][:5]\n",
    "sigs, labels = [],[]\n",
    "cropper = CropSignal(1000*CLIP_LENGTH, pad_mode='repeat')\n",
    "remove_silence = RemoveSilence()\n",
    "for i in pb(range(len(files_10))):\n",
    "    sigs.append(cropper(remove_silence(oa(i))).sig)\n",
    "    labels.append(labeler(files_10[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3842, 3842)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sigs), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(3842*.8)\n",
    "train_idxs = torch.randperm(3842)[:train_size]\n",
    "valid_idxs = [i for i in range(3842) if i not in train_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_idxs) + len(valid_idxs) == len(sigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [sigs[idx].numpy() for idx in train_idxs]\n",
    "y_train = [labels[idx] for idx in train_idxs]\n",
    "x_valid = [sigs[idx].numpy() for idx in valid_idxs]\n",
    "y_valid = [labels[idx] for idx in valid_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3073, 3073, 769, 769]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, (x_train, y_train, x_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3073, 1, 32000), (769, 1, 32000))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_x_train = np.stack(x_train).astype(np.float64)\n",
    "np_x_valid = np.stack(x_valid).astype(np.float64)\n",
    "np_x_train.shape, np_x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2i_f = lambda x: 5*(x[0]=='m') + int(x[-1]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y_train = np.array(list(map(o2i_f, y_train)))\n",
    "np_y_valid = np.array(list(map(o2i_f, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 7, 9, ..., 7, 8, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3073, 1, 32000), (3073,), (769, 1, 32000), (769,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_x_train.shape, np_y_train.shape, np_x_valid.shape, np_y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.5069507694461624e-05, 0.028227341577238208)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_x_train.mean(), np_x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_x_train = (np_x_train - np_x_train.mean(axis = 2, keepdims = True)) / (np_x_train.std(axis = 2, keepdims = True) + 1e-8)\n",
    "np_x_valid = (np_x_valid - np_x_valid.mean(axis = 2, keepdims = True)) / (np_x_valid.std(axis = 2, keepdims = True) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4730514172839015"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_x_train[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.7392802814417085e-20, 0.9999995557310202)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_x_train.mean(), np_x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3073, 1, 32000])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train_tensor = torch.tensor(np_x_train, device=device)\n",
    "X_valid_tensor = torch.tensor(np_x_valid, device=device)\n",
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, features, seq_len = X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCKET(nn.Module):\n",
    "    def __init__(self, c_in, seq_len, n_kernels=10000, kss=[7, 9, 11], stride=7):\n",
    "        '''\n",
    "        ROCKET is a Pytorch implementation of the ROCKET methods generate_kernels and apply_kernels that can be used \n",
    "        with univariate and multivariate time series.\n",
    "        Input: is a 3d torch tensor of type torch.float32. When used with univariate TS, make sure you transform\n",
    "        the 2d to 3d by adding unsqueeze(1)\n",
    "        c_in: number of channels in (features). For univariate c_in is 1.\n",
    "        seq_len: sequence length (is the last dimension of the input)\n",
    "        '''\n",
    "        super().__init__()\n",
    "        kss = [ks for ks in kss if ks < seq_len]\n",
    "        convs = nn.ModuleList()\n",
    "        for i in range(n_kernels):\n",
    "            ks = np.random.choice(kss)\n",
    "            dilation = 2**np.random.uniform(0, np.log2((seq_len - 1) // (ks - 1)))\n",
    "            padding = int((ks - 1) * dilation // 2) if np.random.randint(2) == 1 else 0\n",
    "            weight = torch.normal(0, 1, (1, c_in, ks))\n",
    "            weight -= weight.mean()\n",
    "            bias = 2 * (torch.rand(1) - .5)\n",
    "            layer = nn.Conv1d(c_in, 1, ks, stride=stride, padding=2 * padding, dilation=int(dilation), bias=True)\n",
    "            layer.weight = torch.nn.Parameter(weight, requires_grad=False)\n",
    "            layer.bias = torch.nn.Parameter(bias, requires_grad=False)\n",
    "            convs.append(layer)\n",
    "        self.convs = convs\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kss = kss\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_kernels):\n",
    "            x = x.float()\n",
    "            out = self.convs[i](x)\n",
    "            _max = out.max(dim=-1).values\n",
    "            _ppv = torch.gt(out, 0).sum(dim=-1).float() / out.shape[-1]\n",
    "            cat = torch.cat((_max, _ppv), dim=-1)\n",
    "            output = cat if i == 0 else torch.cat((output, cat), dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ROCKET(features, seq_len, n_kernels=1000, kss=[7, 9, 11], stride=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 3.78 s, total: 4.99 s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_tfm = model(X_train_tensor)\n",
    "X_valid_tfm = model(X_valid_tensor)\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 7), normalize=True)\n",
    "classifier.fit(X_train_tfm.cpu(), y_train)\n",
    "classifier.score(X_valid_tfm.cpu(), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988296488946684"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_test_torch(runs, candidate_lengths, stride, num_kernels, seq_length):\n",
    "    times, scores = [],[]\n",
    "    for i in range(runs):\n",
    "        start = time.time()\n",
    "        model = ROCKET(features, seq_len, n_kernels=num_kernels, kss=candidate_lengths, stride=stride).to(device)\n",
    "        X_train_tfm = model(X_train_tensor)\n",
    "        X_valid_tfm = model(X_valid_tensor)\n",
    "        classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 7), normalize=True)\n",
    "        classifier.fit(X_train_tfm.cpu(), y_train)\n",
    "        score = classifier.score(X_valid_tfm.cpu(), y_valid)\n",
    "        t = time.time()-start\n",
    "        scores.append(score)\n",
    "        times.append(t)\n",
    "        print(\"Finished Run\", i+1, \"Score:\", round(score, 3), \"Time:\", round(t,3))\n",
    "    return times, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Run 1 Score: 0.993 Time: 104.952\n",
      "Finished Run 2 Score: 0.993 Time: 100.857\n",
      "Finished Run 3 Score: 0.99 Time: 100.857\n",
      "Finished Run 4 Score: 0.993 Time: 98.237\n",
      "Finished Run 5 Score: 0.993 Time: 90.696\n",
      "Finished Run 6 Score: 0.996 Time: 89.319\n",
      "Finished Run 7 Score: 0.993 Time: 86.361\n",
      "Finished Run 8 Score: 0.993 Time: 86.523\n",
      "Finished Run 9 Score: 0.993 Time: 82.374\n",
      "Finished Run 10 Score: 0.991 Time: 83.192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([104.95241570472717,\n",
       "  100.85698008537292,\n",
       "  100.85703492164612,\n",
       "  98.23719668388367,\n",
       "  90.69618582725525,\n",
       "  89.31893134117126,\n",
       "  86.3606321811676,\n",
       "  86.52349829673767,\n",
       "  82.37362384796143,\n",
       "  83.1916491985321],\n",
       " [0.9934980494148244,\n",
       "  0.9934980494148244,\n",
       "  0.9895968790637191,\n",
       "  0.9934980494148244,\n",
       "  0.9934980494148244,\n",
       "  0.9960988296488946,\n",
       "  0.9934980494148244,\n",
       "  0.9934980494148244,\n",
       "  0.9934980494148244,\n",
       "  0.9908972691807543])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing_test_torch(10, np.array((7,9,11)), stride=3, num_kernels=1000, seq_length=32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.device\n",
    "X_valid_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
